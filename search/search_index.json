{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pytest-harvest","text":"<p>Store data created during your <code>pytest</code> tests execution, and retrieve it at the end of the session, e.g. for applicative benchmarking purposes.</p> <p> </p> <p> </p> <p>now compliant with <code>pytest-xdist</code>! check it out</p> <p><code>pytest</code> is a great tool to write test logic once and then generate multiple tests from parameters. Its fixture mechanism provides a cool way to inject dependencies in your tests.</p> <p>At the end of a test session, you can already collect various data about the tests that have been run. But it is a bit cumbersome to get it right, and requires you to write a plugin (see this advice).</p> <p>Besides, as opposed to parameters (<code>@pytest.mark.parametrize</code>), <code>pytest</code> purposedly does not keep fixtures (<code>@pytest.fixture</code>) in memory, because in general that would just be a waste of memory. Therefore you are currently not able to retrieve fixture values at the end of the session.</p> <p>Finally, what about other kind of applicative results that you produce during test execution ? There is no current mechanism in <code>pytest</code> to manage that.</p> <p>With <code>pytest-harvest</code>:</p> <ul> <li> <p>you can store all instances of a fixture with <code>@saved_fixture</code>, so that they remain available until the end of the test session. If you're only interested in some aspects of the fixture, you can store \"views\" instead.</p> </li> <li> <p>you can use the special <code>results_bag</code> fixture to collect interesting results within your tests.</p> </li> <li> <p>you can use the special <code>[session/module]_results_[dct/df]</code> fixtures to easily collect all available data at the end of a session or module, without having to register <code>pytest</code> hooks. The status, duration and parameters of all tests become easily available both as dictionary or <code>pandas</code> dataframe, and your saved fixtures and results are there too. </p> </li> <li> <p>you can create your own variants of the above thanks to the API, for more customized data collection and synthesis.</p> </li> </ul> <p>With all that, you can now easily create applicative benchmarks. See pytest-patterns for an example of data science benchmark.</p>"},{"location":"#installing","title":"Installing","text":"<pre><code>&gt; pip install pytest_harvest\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#a-collecting-fixture-instances","title":"a- Collecting fixture instances","text":"<p>Simply use the <code>@saved_fixture</code> decorator on your fixtures to declare that their instances must be saved. By default they are saved in a session-scoped <code>fixture_store</code> fixture that you can therefore grab and inspect in other tests or in any compliant pytest entry point:</p> <pre><code>import pytest\nfrom pytest_harvest import saved_fixture\n\n@pytest.fixture(params=range(2))\n@saved_fixture\ndef person(request):\n    \"\"\"\n    A dummy fixture, parametrized so that it has two instances\n    \"\"\"\n    if request.param == 0:\n        return \"world\"\n    elif request.param == 1:\n        return \"self\"\n\ndef test_foo(person):\n    \"\"\"\n    A dummy test, executed for each `person` fixture available\n    \"\"\"\n    print('\\n   hello, ' + person + ' !')\n\ndef test_synthesis(fixture_store):\n    \"\"\"\n    In this test we inspect the contents of the fixture store so far,\n    and check that the 'person' entry contains a dict &lt;test_id&gt;: &lt;person&gt;\n    \"\"\"\n    # print the keys in the store\n    print(\"\\n   Available `fixture_store` keys:\")\n    for k in fixture_store:\n        print(\"    - '%s'\" % k)\n\n    # print what is available for the 'person' entry\n    print(\"\\n   Contents of `fixture_store['person']`:\")\n    for k, v in fixture_store['person'].items():\n        print(\"    - '%s': %s\" % (k, v))\n</code></pre> <p>Let's execute it:</p> <pre><code>&gt;&gt;&gt; pytest -s -v\n\n============================= test session starts =============================\n...\ncollecting ... collected 3 items\ntest_doc_basic_saved_fixture.py::test_foo[0] \n   hello, world !\nPASSED\ntest_doc_basic_saved_fixture.py::test_foo[1] \n   hello, self !\nPASSED\ntest_doc_basic_saved_fixture.py::test_synthesis \n   Available `fixture_store` keys:\n    - 'person'\n\n   Contents of `fixture_store['person']`:\n    - 'test_doc_basic_saved_fixture.py::test_foo[0]': world\n    - 'test_doc_basic_saved_fixture.py::test_foo[1]': self\nPASSED\n\n========================== 3 passed in 0.09 seconds ===========================\n</code></pre> <p>As you can see, the <code>fixture_store</code> contains one entry for each saved fixture, and this entry's value is a dictionary of <code>{&lt;test_id&gt;: &lt;fixture_value&gt;}</code>.  We will see below how to combine this information with information already available in pytest (test status, duration...).</p>"},{"location":"#collecting-fixture-views","title":"Collecting fixture views","text":"<p>Sometimes you are not interested in storing the whole fixture but maybe just some aspect of it. For example maybe the fixture is a huge dataset, and you just wish to remember a few characteristics about it.</p> <p>Simply use the <code>views=</code> argument in <code>@saved_fixture</code> to save views instead of the fixture itself. That argument should contain a dictionary of <code>{&lt;view_key&gt;: &lt;view_creation_function&gt;}</code>.</p> <p>In the previous example if we only want to save the first and last character of the <code>person</code> fixture, we can do:</p> <pre><code>@pytest.fixture(params=range(2))\n@saved_fixture(views={'person_initial': lambda p: p[0], \n                      'person_last_char': lambda p: p[-1]})\ndef person(request):\n    \"\"\"\n    A dummy fixture, parametrized so that it has two instances\n    \"\"\"\n    if request.param == 0:\n        return \"world\"\n    elif request.param == 1:\n        return \"self\"\n</code></pre> <p>The fixture store will then contain as many entries as there are views.</p>"},{"location":"#b-collecting-test-artifacts","title":"b- Collecting test artifacts","text":"<p>Simply use the <code>results_bag</code> fixture in your tests and you'll be able to store items in it. This object behaves like a munch: if you create/read a field it will create/read a dictionary entry. By default the <code>results_bag</code> fixture is stored in the <code>fixture_store</code> so you can retrieve it at the end as shown previously.</p> <pre><code>from datetime import datetime\nimport pytest\n\n@pytest.mark.parametrize('p', ['world', 'self'], ids=str)\ndef test_foo(p, results_bag):\n    \"\"\"\n    A dummy test, parametrized so that it is executed twice\n    \"\"\"\n    print('\\n   hello, ' + p + ' !')\n\n    # Let's store some things in the results bag\n    results_bag.nb_letters = len(p)\n    results_bag.current_time = datetime.now().isoformat()\n\ndef test_synthesis(fixture_store):\n    \"\"\"\n    In this test we inspect the contents of the fixture store so far, and \n    check that the 'results_bag' entry contains a dict &lt;test_id&gt;: &lt;results_bag&gt;\n    \"\"\"\n    # print the keys in the store\n    print(\"\\n   Available `fixture_store` keys:\")\n    for k in fixture_store:\n        print(\"    - '%s'\" % k)\n\n    # print what is available for the 'results_bag' entry\n    print(\"\\n   Contents of `fixture_store['results_bag']`:\")\n    for k, v in fixture_store['results_bag'].items():\n        print(\"    - '%s':\" % k)\n        for kk, vv in v.items():\n            print(\"      - '%s': %s\" % (kk, vv))\n</code></pre> <p>Let's execute it:</p> <pre><code>&gt;&gt;&gt; pytest -s -v\n\n============================= test session starts =============================\n...\ncollecting ... collected 3 items\ntest_doc_basic_results_bag.py::test_foo[world] \n   hello, world !\nPASSED\ntest_doc_basic_results_bag.py::test_foo[self] \n   hello, self !\nPASSED\ntest_doc_basic_results_bag.py::test_synthesis \n   Available `fixture_store` keys:\n    - 'results_bag'\n\n   Contents of `fixture_store['results_bag']`:\n    - 'test_doc_basic_results_bag.py::test_foo[world]':\n      - 'nb_letters': 5\n      - 'current_time': 2018-12-08T22:20:10.695791\n    - 'test_doc_basic_results_bag.py::test_foo[self]':\n      - 'nb_letters': 4\n      - 'current_time': 2018-12-08T22:20:10.700791\nPASSED\n\n========================== 3 passed in 0.05 seconds ===========================\n</code></pre> <p>As in previous example, the <code>fixture_store</code> contains one entry for <code>'results_bag'</code>, and this entry's value is a dictionary of <code>{&lt;test_id&gt;: &lt;results_bag&gt;}</code>. We can therefore access all values stored within each test (here, <code>nb_letters</code> and <code>current_time</code>). </p> <p>We will see below how to combine this information with information already available in pytest.</p>"},{"location":"#c-collecting-a-synthesis","title":"c- Collecting a synthesis","text":"<p>as a <code>dict</code></p> <p>Simply use the <code>module_results_dct</code> fixture to get a dictionary containing the test results in that module, so far. You can use this fixture in a test as shown below (<code>test_synthesis</code>) or in any compliant pytest entry point. </p> <pre><code>import pytest\nimport time\n\n@pytest.mark.parametrize('p', ['world', 'self'], ids=str)\ndef test_foo(p):\n    \"\"\"\n    A dummy test, parametrized so that it is executed twice\n    \"\"\"\n    print('\\n   hello, ' + p + ' !')\n    time.sleep(len(p) / 10)\n\ndef test_synthesis(module_results_dct):\n    \"\"\"\n    In this test we just look at the synthesis of all tests \n    executed before it, in that module.\n    \"\"\"\n    # print the keys in the synthesis dictionary\n    print(\"\\n   Available `module_results_dct` keys:\")\n    for k in module_results_dct:\n        print(\"    - \" + k)\n\n    # print what is available for a single test\n    print(\"\\n   Contents of 'test_foo[world]':\")\n    for k, v in module_results_dct['test_foo[world]'].items():\n        if k != 'status_details':\n            print(\"    - '%s': %s\" % (k, v))\n        else:\n            print(\"    - '%s':\" % k)\n            for kk, vv in v.items():\n                print(\"      - '%s': %s\" % (kk, vv))\n</code></pre> <p>Let's execute it:</p> <pre><code>&gt;&gt;&gt; pytest -s -v\n\n============================= test session starts =============================\n...\ncollecting ... collected 3 items\ntest_doc_basic.py::test_foo[world]\n   hello, world !\nPASSED\ntest_doc_basic.py::test_foo[self]\n   hello, self !\nPASSED\ntest_doc_basic.py::test_synthesis \n   Available `module_results_dct` keys:\n    - test_foo[world]\n    - test_foo[self]\n\n   Contents of 'test_foo[world]':\n    - 'pytest_obj': &lt;function test_foo at 0x0000000005A7DEA0&gt;\n    - 'status': passed\n    - 'duration_ms': 500.0283718109131\n    - 'status_details':\n      - 'setup': ('passed', 3.0002593994140625)\n      - 'call': ('passed', 500.0283718109131)\n      - 'teardown': ('passed', 2.0003318786621094)\n    - 'params': OrderedDict([('p', 'world')])\n    - 'fixtures': OrderedDict()\nPASSED\n\n========================== 3 passed in 0.05 seconds ===========================\n</code></pre> <p>As you can see, for each test node id you get a dictionary containing</p> <ul> <li><code>'pytest_obj'</code>the object containing the test code</li> <li><code>'status'</code> the status of the test (passed/skipped/failed)</li> <li><code>'duration_ms'</code> the duration of the test as measured by pytest (only the \"call\" step is measured here, not setup nor teardown times)</li> <li><code>'status_details'</code>: details (status and duration) for each pytest phase</li> <li><code>'params'</code>the parameters used in this test (both in the test function AND the fixtures)</li> <li><code>'fixtures'</code> the saved fixture instances (not parameters) for this test. Here we see the saved fixtures and result bags, if any (see below for a complete example) </li> </ul> <p>Note: if you need the synthesis to contain all tests of the session instead of just the current module, use fixture <code>session_results_dct</code> instead.</p> <p>as a <code>DataFrame</code></p> <p>Simply use the <code>module_results_df</code> fixture instead of <code>module_results_dct</code> (note the <code>df</code> suffix instead of <code>dct</code>) to get the same contents as a table, which might be more convenient for statistics and aggregations of all sorts. Note: you have to have <code>pandas</code> installed for this fixture to be available.</p> <p>Replacing the above <code>test_synthesis</code> function with </p> <pre><code>def test_synthesis(module_results_df):\n    \"\"\"\n    In this variant we use the 'dataframe' fixture\n    \"\"\"\n    # print the synthesis dataframe\n    print(\"\\n   `module_results_df` dataframe:\\n\")\n    print(module_results_df)\n</code></pre> <p>yields:</p> <pre><code>&gt;&gt;&gt; pytest -s -v\n\n============================= test session starts =============================\n...\ncollecting ... collected 3 items\ntest_doc_basic.py::test_foo[world] \n   hello, world !\nPASSED\ntest_doc_basic.py::test_foo[self] \n   hello, self !\nPASSED\ntest_doc_basic.py::test_synthesis \n   `module_results_df` dataframe:\n\n                 status  duration_ms      p\ntest_id                                    \ntest_foo[world]  passed   500.028610  world\ntest_foo[self]   passed   400.022745   self\nPASSED\n\n========================== 3 passed in 0.05 seconds ===========================\n</code></pre> <p>As can be seen above, each row in the dataframe corresponds to a test (the index is the test id), and the various information are presented in columns. As opposed to the dictionary version, status details are not provided.</p> <p>Note: as for the dict version, if you need the synthesis to contain all tests of the session instead of just the current module, use fixture <code>session_results_df</code> instead.</p>"},{"location":"#d-collecting-all-at-once","title":"d- collecting all at once","text":"<p>We have seen first how to collect saved fixtures, and test artifacts thanks to results bags. Then we saw how to collect pytest status and duration information, as well as parameters. </p> <p>You may now wonder how to collect all of this in a single handy object ? Well, the answer is quite simple: you have nothing more to do. Indeed, the <code>[module/session]_results_[dct/df]</code> fixtures that we saw in previous chapter will by default contain all saved fixtures and results bags. </p> <p>Let's try it:</p> <pre><code>import time\nfrom datetime import datetime\nfrom tabulate import tabulate\n\nimport pytest\nfrom pytest_harvest import saved_fixture\n\n@pytest.fixture(params=range(2))\n@saved_fixture\ndef person(request):\n    \"\"\"\n    A dummy fixture, parametrized so that it has two instances\n    \"\"\"\n    if request.param == 0:\n        return \"world\"\n    elif request.param == 1:\n        return \"self\"\n\n@pytest.mark.parametrize('double_sleep_time', [False, True], ids=str)\ndef test_foo(double_sleep_time, person, results_bag):\n    \"\"\"\n    A dummy test, parametrized so that it is executed twice.\n    \"\"\"\n    print('\\n   hello, ' + person + ' !')\n    time.sleep(len(person) / 10 * (2 if double_sleep_time else 1))\n\n    # Let's store some things in the results bag\n    results_bag.nb_letters = len(person)\n    results_bag.current_time = datetime.now().isoformat()\n\ndef test_synthesis(module_results_df):\n    \"\"\"\n    In this test we just look at the synthesis of all tests\n    executed before it, in that module.\n    \"\"\"\n    # print the synthesis dataframe\n    print(\"\\n   `module_results_df` dataframe:\\n\")\n\n    # we use 'tabulate' for a nicer output format\n    print(tabulate(module_results_df, headers='keys', tablefmt=\"pipe\"))\n</code></pre> <p>yields</p> <pre><code>&gt;&gt;&gt; pytest -s -v\n\n============================= test session starts =============================\n...\ncollecting ... collected 5 items\ntest_doc_basic_df_all.py::test_foo[0-False] \ntest_doc_basic_df_all.py::test_foo[0-True] \ntest_doc_basic_df_all.py::test_foo[1-False] \ntest_doc_basic_df_all.py::test_foo[1-True] \ntest_doc_basic_df_all.py::test_synthesis \n   hello, world !\nPASSED\n   hello, world !\nPASSED\n   hello, self !\nPASSED\n   hello, self !\nPASSED\n   `module_results_df` dataframe:\n\n| test_id           | pytest_obj                                | status   |   duration_ms | double_sleep_time   |   person_param | person   |   nb_letters | current_time               |\n|:------------------|:------------------------------------------|:---------|--------------:|:--------------------|---------------:|:---------|-------------:|:---------------------------|\n| test_foo[0-False] | &lt;function test_foo at 0x0000000004F8C488&gt; | passed   |       500.029 | False               |              0 | world    |            5 | 2018-12-10T22:06:32.279561 |\n| test_foo[0-True]  | &lt;function test_foo at 0x0000000004F8C488&gt; | passed   |      1000.06  | True                |              0 | world    |            5 | 2018-12-10T22:06:33.283618 |\n| test_foo[1-False] | &lt;function test_foo at 0x0000000004F8C488&gt; | passed   |       400.023 | False               |              1 | self     |            4 | 2018-12-10T22:06:33.687641 |\n| test_foo[1-True]  | &lt;function test_foo at 0x0000000004F8C488&gt; | passed   |       800.046 | True                |              1 | self     |            4 | 2018-12-10T22:06:34.491687 |\nPASSED\n\n========================== 5 passed in 3.87 seconds ===========================\n</code></pre> <p>So we see here that we get all the information in a single handy table object: for each test, we get its status, duration, parameters (<code>double_sleep_time</code>, <code>person_param</code>), fixtures (<code>person</code>) and results (<code>nb_letters</code>, <code>current_time</code>).</p> <p>Of course you can still get the same information as a dictionary, and chose to get it for the whole session or for a specific module (see previous chapter). </p>"},{"location":"#e-advanced-usage","title":"e- advanced usage","text":"<p>All the behaviours described above are pre-wired using fixtures, to help most users getting started. For each fixture described above there is an equivalent method in <code>pytest-harvest</code> API, so that you may access the same information from within a pytest hook such as <code>pytest_sessionfinish(session)</code>:</p> <ul> <li><code>fixture_store</code> fixture: <code>get_fixture_store(session)</code></li> <li><code>module_results_dct</code> fixture: <code>get_module_results_dct(session, module_name)</code></li> <li><code>module_results_df</code> fixture: <code>get_module_results_df(session, module_name)</code></li> <li><code>session_results_dct</code> fixture: <code>get_session_results_dct(session)</code></li> <li><code>session_results_df</code> fixture: <code>get_session_results_df(session)</code></li> </ul> <p>Finally, these fixtures and equivalent methods are nothing but pre-wiring of more generic capabilities, that are offered in this library as well. So if these pre-wired objects do not suit your needs and you wish to create custom synthesis, custom store objects, custom results bags... see advanced usage page.</p>"},{"location":"#compliance-with-the-pytest-ecosystem","title":"Compliance with the pytest ecosystem","text":"<p>This plugin mostly relies on the fixtures mechanism and the <code>pytest_runtest_makereport</code> hook. It should therefore be quite portable across pytest versions (at least it is tested against pytest 2, 3, 4, 5, for both python 2 and 3).</p>"},{"location":"#pytest-x-dist","title":"pytest x-dist","text":"<p>You may wish to rely on <code>pytest-xdist</code> to parallelize/distribute your tests. In that case, you can not rely on the <code>[module/session]_results_[dct/df]</code> fixtures described previously to collect your synthesis because as of today there is no way to ensure that these methods will run last on the workers, and to run them at all on the master. So instead of using these fixtures, simply use the equivalent methods <code>get_[module/session]_results_[dct/df](session, [module_name])</code> in a pytest hook, and <code>pytest-harvest</code> will take care of the rest.</p> <p>More precisely, when <code>pytest-xdist</code> is used to distribute tests, worker node results are automatically stored by <code>pytest-harvest</code> in a file at the end of their respective pytest session using pickle, in a temporary <code>.xdist_harvested/</code> folder. These results are automatically retrieved and consolidated when any of the <code>get_[module/session]_results_[dct/df]</code> method is called from the master node. Finally, the temporary folder is deleted at the end of master node session. You can use the <code>get_[module/session]_results_[dct/df]</code> methods in any pytest hook on the \"master\" node, for example in the <code>pytest_sessionfinish</code> hook. The methods continue to work on worker nodes, so to know if you are in the master node, a <code>is_main_process</code> function is provided.</p> <p>Below is an example of <code>conftest.py</code> that works both with and without <code>pytest-xdist</code> enabled, and within both master an worker nodes:</p> <pre><code>from pytest_harvest import is_main_process, get_xdist_worker_id, \\\n                           get_session_results_df\n\ndef pytest_sessionfinish(session):\n    \"\"\" Gather all results and save them to a csv. \n    Works both on worker and master nodes, and also with xdist disabled\"\"\"\n\n    session_results_df = get_session_results_df(session)\n    suffix = 'all' if is_main_process(session) else get_xdist_worker_id(session)\n    session_results_df.to_csv('results_%s.csv' % suffix)\n</code></pre> <p>Note: you can also do the persist/restore operation yourself using the hooks provided. See <code>newhooks</code> for details. Below is a <code>contest.py</code> example doing the same than the default behaviour, but with a different temporary folder:</p> <pre><code>from pathlib import Path\nfrom shutil import rmtree\nimport pickle\nfrom logging import warning\n\n# Define the folder in which temporary worker's results will be stored\nRESULTS_PATH = Path('./.xdist_results/')\nRESULTS_PATH.mkdir(exist_ok=True)\n\ndef pytest_harvest_xdist_init():\n    # reset the recipient folder\n    if RESULTS_PATH.exists():\n        rmtree(RESULTS_PATH)\n    RESULTS_PATH.mkdir(exist_ok=False)\n    return True\n\ndef pytest_harvest_xdist_worker_dump(worker_id, session_items, fixture_store):\n    # persist session_items and fixture_store in the file system\n    with open(RESULTS_PATH / ('%s.pkl' % worker_id), 'wb') as f:\n        try:\n            pickle.dump((session_items, fixture_store), f)\n        except Exception as e:\n            warning(\"Error while pickling worker %s's harvested results: \" \n                    \"[%s] %s\", (worker_id, e.__class__, e))\n    return True\n\ndef pytest_harvest_xdist_load():\n    # restore the saved objects from file system\n    workers_saved_material = dict()\n    for pkl_file in RESULTS_PATH.glob('*.pkl'):\n        wid = pkl_file.stem\n        with pkl_file.open('rb') as f:\n            workers_saved_material[wid] = pickle.load(f)\n    return workers_saved_material\n\ndef pytest_harvest_xdist_cleanup():\n    # delete all temporary pickle files\n    rmtree(RESULTS_PATH)\n    return True\n</code></pre>"},{"location":"#main-features-benefits","title":"Main features / benefits","text":"<ul> <li> <p>Collect test execution information easily: with the default <code>[module/session]_results_[dct/df]</code> fixtures, and with <code>get_session_synthesis_dct(session)</code> (advanced users), you can collect all the information you need, without the hassle of writing hooks. </p> </li> <li> <p>Store selected fixtures declaratively: simply decorate your fixture with <code>@saved_fixture</code> and all fixture values will be stored in the default storage. You can use the advanced <code>@saved_fixture(store)</code> to customize the storage (a variable or another fixture).</p> </li> <li> <p>Collect test artifacts: simply use the <code>results_bag</code> fixture to start collecting results from your tests. You can also create your own \"results bags\" fixtures (advanced). It makes it very easy to create applicative benchmarks, for example for data science.</p> </li> <li> <p>Highly configurable: storage object (for storing fixtures) or results bag objects (for collecting results from tests) can be of any object type of your choice. For results bags, a default type is provided that behaves like a \"munch\" (both a dictionary and an object). See advanced usage page.</p> </li> </ul>"},{"location":"#see-also","title":"See Also","text":"<ul> <li>pytest documentation on parametrize</li> <li>pytest documentation on fixtures</li> <li>pytest-patterns, to go further and create for example a data science benchmark by combining this plugin with others.</li> </ul>"},{"location":"#others","title":"Others","text":"<p>Do you like this library ? You might also like my other python libraries </p>"},{"location":"#want-to-contribute","title":"Want to contribute ?","text":"<p>Details on the github page: https://github.com/smarie/python-pytest-harvest</p>"},{"location":"advanced_usage/","title":"Advanced Usage","text":"<p>You have seen in the introduction how to use the pre-wired fixtures to perform most comon tasks. The sections below explore, for each topic, the internals that are used behind the scenes, so that you are able to create custom behaviours if the default ones do not match your needs.</p>"},{"location":"advanced_usage/#0-prerequisite-how-to-write-session-teardown-code","title":"0- Prerequisite: how to write session teardown code","text":"<p>In order to be able to retrieve all the information that we will store, we will need to execute our retrieval/synthesis code at the end of the entire test session. </p> <p><code>pytest</code> currently provides several ways to do this:</p> <ul> <li>through a test (put it at the end of the latest test file to ensure execution at the end):</li> </ul> <pre><code>def test_synthesis(request):\n    # you can access the session from the injected 'request':\n    session = request.session\n    print(\"&lt;Put here your synthesis code&gt;\")\n</code></pre> <ul> <li>through a generator (yield) session-scoped fixture (put this in any of your test files or in the <code>conftest.py</code> file):</li> </ul> <pre><code># Note: for pytest&lt;3.0 you have to use @pytest.yield_fixture instead\n@pytest.fixture(scope='session', autouse=True)\ndef my_cooler_session_finish(request):\n    yield\n    # you can access the session from the injected 'request':\n    session = request.session\n    print(\"&lt;Put here your synthesis code&gt;\")\n</code></pre> <ul> <li>through a normal session-scoped fixture (put this in any of your test files or in the <code>conftest.py</code> file):</li> </ul> <pre><code>@pytest.fixture(scope=\"session\", autouse=True)\ndef my_session_finish(request):\n    def _end():\n        # you can access the session from the injected 'request':\n        session = request.session\n        print(\"&lt;Put here your synthesis code&gt;\")\n    request.addfinalizer(_end)\n</code></pre> <ul> <li>through the session finish hook (you have to write this function in the <code>conftest.py</code> file):</li> </ul> <pre><code>def pytest_sessionfinish(session, exitstatus):\n    print(\"&lt;Put here your synthesis code&gt;\")\n</code></pre> <p>All seem completely equivalent for the usage of <code>pytest_harvest</code>. I personally prefer the \"fixture\" style because you can have several of them instead of a monolithic teardown hook. Besides they can be put in the test files so I typically put them as close as possible to the tests that store the data, so as to ensure maintainability (data creation/storage and data retrieval/synthesis code are in the same file).</p>"},{"location":"advanced_usage/#1-collecting-tests-status-and-parameters","title":"1- Collecting tests status and parameters","text":"<p>Pytest already stores some information out of the box concerning tests that have run. In addition you can follow this example to retrieve more, but it requires you to write a hook so it is not very convenient. </p> <p>Instead, you can easily retrieve all of that thanks to the <code>get_session_synthesis_dct(session)</code> utility function. For example let's assume you have this parametrized test with a parametrized fixture:</p> <pre><code># unparametrized fixture\n@pytest.fixture\ndef dummy():\n    return \"hey there !\"\n\n# parametrized fixture\n@pytest.fixture(param=[1, 2])\ndef a_number_str(request):\n    return \"my_fix #%s\" % request.param\n\n# parametrized test using the fixtures\n@pytest.mark.parametrize('p', ['hello', 'world'], ids=str)\ndef test_foo(p, a_number_str, dummy):\n    print(p + a_number_str)\n</code></pre> <p>When running it, 4 tests are executed:</p> <pre><code>&gt;&gt;&gt; pytest\n\n============================= test session starts =============================\ncollected 4 items                                                              \n\npath/to/test_file.py::test_foo[1-hello] PASSED [ 25%]\npath/to/test_file.py::test_foo[1-world] PASSED [ 50%]\npath/to/test_file.py::test_foo[2-hello] PASSED [ 75%]\npath/to/test_file.py::test_foo[2-world] PASSED [100%]\n\n========================== 4 passed in 0.11 seconds ===========================\n</code></pre> <p>let's retrieve the available information at the end of the session. The easiest way is to write a \"last test\" and make sure it is executed after all the other as shown below, but there are other ways as shown above:</p> <pre><code>from pytest_harvest import get_session_synthesis_dct\n\ndef test_synthesis(request):\n    synth_dct = get_session_synthesis_dct(request.session, status_details=True)\n    print(dict(synth_dct))\n</code></pre> <p>It yields</p> <pre><code>{\n 'path/to/test_file.py::test_foo[1-hello]': {\n            'pytest_duration': 0.0010001659393310547,\n            'pytest_obj': &lt;function test_foo at 0x0000000004C13B70&gt;,\n            'pytest_params': {'a_number_str_param': 1, 'p': 'hello'},\n            'pytest_status': 'passed',\n            'pytest_status_details': {'call': ('passed', 0.0010001659393310547),\n                                      'setup': ('passed', 0.013001203536987305),\n                                      'teardown': ('passed', 0.0)\n                                     }\n             },\n 'path/to/test_file.py::test_foo[1-world]': {\n            'pytest_duration': 0.0,\n            'pytest_obj': &lt;function test_foo at 0x0000000004C13B70&gt;,\n            'pytest_params': {'a_number_str_param': 1, 'p': 'world'},\n            'pytest_status': 'passed',\n            'pytest_status_details': {'call': ('passed', 0.0),\n                                      'setup': ('passed', 0.0),\n                                      'teardown': ('passed', 0.0)\n                                     }\n             },\n 'path/to/test_file.py::test_foo[2-hello]': {\n            'pytest_duration': 0.0010001659393310547,\n            'pytest_obj': &lt;function test_foo at 0x0000000004C13B70&gt;,\n            'pytest_params': {'a_number_str_param': 2, 'p': 'hello'},\n            'pytest_status': 'passed',\n            'pytest_status_details': {'call': ('passed', 0.0010001659393310547), \n                                      'setup': ('passed', 0.0010001659393310547),\n                                      'teardown': ('passed', 0.0)\n                                      }\n             },\n 'path/to/test_file.py::test_foo[2-world]': {\n            'pytest_duration': 0.0,\n            'pytest_obj': &lt;function test_foo at 0x0000000004C13B70&gt;,\n            'pytest_params': {'a_number_str_param': 2, 'p': 'world'},\n            'pytest_status': 'passed',\n            'pytest_status_details': {'call': ('passed', 0.0),\n                                      'setup': ('passed', 0.0010001659393310547),\n                                      'teardown': ('passed', 0.0)\n                                      }\n            }\n}\n</code></pre> <p>As you can see for each test node id you get a dictionary containing</p> <ul> <li><code>'pytest_obj'</code>the object containing the test code</li> <li><code>'pytest_status'</code> the status and <code>'pytest_duration'</code> the duration of the test</li> <li><code>'pytest_params'</code>the parameters used in this test (both in the test function AND the fixture)</li> <li><code>'pytest_status_details'</code> a dictionary containing the status details for each pytest internal stages: setup, call, and teardown. </li> </ul> <p>status and duration aggregation</p> <p>that the global status corresponds to an aggregation of the status of each of those stages (setup, call, teardown), but the global duration is only the duration of the \"call\" stage - after all we do not care about how long it took to setup and teardown.</p> <p>In addition, you can also use the following companion methods : </p> <ul> <li><code>filter_session_items(session, filter=None)</code> is the filtering method used behind the scenes. <code>pytest_item_matches_filter</code> is the inner method used to test if a single item matches the filter.</li> <li><code>get_all_pytest_param_names(session)</code> lists all unique parameter names used, with optional filtering capabilities</li> <li><code>is_pytest_incomplete(item)</code>, <code>get_pytest_status(item)</code>, <code>get_pytest_param_names(item)</code> and <code>get_pytest_params(item)</code> can be used to analyse a specific item in <code>session.items</code> directly without creating the dictionary.</li> </ul> <p>Finally let's have a closer look above. It seems that after all we have collected the fixtures, right ? For example we see <code>'a_number_str_param': 2</code>. But beware, this is not the fixture. It is the parameter used by the fixture <code>'a_number_str'</code>. To be convinced look at its type: it is an integer, not a string! A more obvious way to confirm that the fixtures are not available, is to see that the <code>'dummy'</code> fixture does not appear at all: indeed it had no parameters.</p> <p>To conclude: the <code>get_session_synthesis_dct(session)</code> utility function allows you to collect many information about the tests, but not the fixtures. To do that you have to use the mechanisms below.</p>"},{"location":"advanced_usage/#2-storingretrieving-fixtures","title":"2- Storing/retrieving fixtures","text":"<p>You can either choose to store fixtures in a plain old variable, or in another, session-scoped, fixture. Both can be achieved using the same decorator <code>@saved_fixture(store)</code>.</p>"},{"location":"advanced_usage/#a-storing-in-a-variable","title":"a- Storing in a variable","text":"<p>Let's create a store. It should be a dict-like object:</p> <pre><code># Create a global store\nSTORE = dict()\n</code></pre> <p>In order to store all created fixture values in this object, simply decorate your fixture with <code>@saved_fixture(STORE)</code>:</p> <pre><code>from pytest\nfrom pytest_harvest import saved_fixture\n\n@pytest.fixture(params=[1, 2])\n@saved_fixture(STORE)\ndef my_fix(request):\n    \"\"\"Each returned fixture value will be saved in the global store\"\"\"\n    return \"my_fix #%s\" % request.param\n</code></pre> <p>You can then retrieve the available information at the end of the session (put this in your session teardown):</p> <pre><code>print(dict(STORE['my_fix']))\n</code></pre> <p>Each saved fixture appears as an ordered dictionary stored under a global key that has its name (here 'my_fix'). In this dictionary, the keys are the test node ids, and the values are the fixture values:</p> <pre><code>{'path/to/test_file.py::test_foo[1]': 'my_fix #1', \n'path/to/test_file.py::test_foo[2]': 'my_fix #2'}\n</code></pre> <p>Note: you can change the key used in the global storage with the <code>key=</code> argument of <code>@saved_fixture</code>. </p>"},{"location":"advanced_usage/#b-storing-in-a-fixture","title":"b- Storing in a fixture","text":"<p>You might want your store to be a fixture itself, instead of a global variable. It is possible if it is session- or module-scoped (in the same module than where it is used). Simply use its name in <code>@saved_fixture</code> and it will work as expected. </p> <p>This enables you to make the code even more readable because you can put the synthesis code in the teardown part of the storage fixture:</p> <pre><code>from pytest\nfrom pytest_harvest import saved_fixture\n\n@pytest.fixture(params=[1, 2])\n@saved_fixture(\"store\")\ndef my_fix(request):\n    \"\"\"Each returned fixture value will be saved in the global store\"\"\"\n    return \"my_fix #%s\" % request.param\n\n# -- the global storage fixture and synthesis creator --\n@pytest.fixture(scope='session', autouse=True)\ndef store():\n    # setup: init the store\n    store = OrderedDict()\n    yield store\n    # teardown: here you can collect all\n    print(dict(store['my_fix']))\n</code></pre> <p>other teardown hooks</p> <p>If you use another teardown hook, you can still retrieve your <code>'store'</code> fixture by using the <code>get_fixture_value(request, 'store')</code> utility function provided in this library. </p> <p>yield_fixture</p> <p>In old versions of pytest, you have to use <code>@pytest.yield_fixture</code> to be allowed to use <code>yield</code> in a fixture.</p>"},{"location":"advanced_usage/#3-creating-results-bags-fixtures-to-collect-test-artifacts","title":"3- Creating \"results bags\" fixtures to collect test artifacts","text":"<p>Now we are able to store fixtures. But what about the data that we create during the tests ? It can be accuracy results, etc.</p> <p>For this, simply use <code>create_results_bag_fixture()</code> to create \"results bags\" fixtures where you can put any data you want:</p> <pre><code>from collections import OrderedDict\nfrom random import random\nimport pytest\nfrom pytest_harvest import create_results_bag_fixture\n\ndef my_algorithm(param, data):\n    # let's return a random accuracy !\n    return random()\n\n@pytest.fixture(params=['A', 'B', 'C'])\ndef dataset(request):\n    return \"my dataset #%s\" % request.param\n\n@pytest.mark.parametrize(\"algo_param\", [1, 2], ids=str)\ndef test_my_app_bench(algo_param, dataset, results_bag):\n    \"\"\"\n    This test applies the algorithm with various parameters (`algo_param`)\n    on various datasets (`dataset`). Accuracies are stored in a results\n    bag (`results_bag`)\n    \"\"\"\n    # apply the algorithm with param `algo_param` on dataset `dataset`\n    accuracy = my_algorithm(algo_param, dataset)\n    # store it in the results bag\n    results_bag.accuracy = accuracy\n\n# -- the results bag fixture --\n# note: depending on your pytest version, the name used by pytest might be\n# the variable name (left) or the one you provide in the 'name' argument so \n# make sure they are identical! \nresults_bag = create_results_bag_fixture('store', name=\"results_bag\")\n\n# -- the global storage fixture and synthesis creator --\n@pytest.fixture(scope='session', autouse=True)\ndef store(request):\n    # setup: init the store\n    store = OrderedDict()\n    yield store\n    # teardown: here you can collect all\n    print(dict(store['results_bag']))\n</code></pre> <p>We can see the correct results collected:</p> <pre><code>{\n'path/to/test_file.py::::test_my_app_bench[A-1]': \n     ResultsBag: {'accuracy': 0.2630766637159053}, \n'path/to/test_file.py::::test_my_app_bench[A-2]': \n     ResultsBag: {'accuracy': 0.6720533462346249}, \n'path/to/test_file.py::::test_my_app_bench[B-1]':\n     ResultsBag: {'accuracy': 0.9121353916881674}, \n'path/to/test_file.py::::test_my_app_bench[B-2]': \n     ResultsBag: {'accuracy': 0.9401074040573346}, \n'path/to/test_file.py::::test_my_app_bench[C-1]': \n     ResultsBag: {'accuracy': 0.01619034700438804},\n'path/to/test_file.py::::test_my_app_bench[C-2]': \n     ResultsBag: {'accuracy': 0.8027244886806986}\n}\n</code></pre> <p>We can of course combine this with the test status and parameters (we saw above how to collect them) if we want to create a synthesis table. This complete story will be available on pytest-patterns.</p> <p>results bag fixtures' storage</p> <p>You declare the storage used in the arguments of <code>create_results_bag_fixture</code>. As this relies on <code>@saved_fixture</code>, you can use both a variable or a session/module-scoped fixture name as we saw in previous chapter. </p>"},{"location":"advanced_usage/#4-creating-a-synthesis-table","title":"4- Creating a Synthesis table","text":"<p>Now that we know</p> <ul> <li>how to retrieve pytest status and parameters</li> <li>how to store and retrieve fixtures</li> <li>and how to store and retrieve applicative results</li> </ul> <p>We can create a synthesis table containing all information available. This is very easy: instead of calling <code>get_session_synthesis_dct</code> with no parameters, give it your <code>store</code> object. Since we want to create a table, we will use the <code>flatten</code> and <code>flatten_more</code> options so that the result does not contain nested dictionaries for the parameters, fixtures, and result bags. Finally we decide that we want the durations expressed in ms (pytest measures them in seconds by default).</p> <pre><code># retrieve the synthesis, merged with the fixture store\nresults_dct = get_session_synthesis_dct(session, fixture_store=store, \n                                        flatten=True, flatten_more='results_bag',\n                                        durations_in_ms=True)\n</code></pre> <p>We can print the first entry:</p> <pre><code>&gt;&gt;&gt; pprint(dict(next(iter(results_dct.values()))))\n\n{'pytest_obj': &lt;function test_my_app_bench at 0x0000000004FF6A60&gt;,\n 'pytest_status': 'passed',\n 'pytest_duration_ms': 0.0,\n 'dataset': 'A',\n 'algo_param': 1,\n 'accuracy': 0.2630766637159053}\n</code></pre> <p>We see that all information is available at the same level: pytest status and duration, parameters (<code>dataset</code> and <code>algo_param</code>), and results (<code>accuracy</code>).</p> <p>Transforming such a flattened dictionary in a table is very easy with <code>pandas</code>:</p> <pre><code>import pandas as pd\nresults_df = pd.DataFrame.from_dict(results_dct, orient='index')\n# (a) remove the full test id path\nresults_df.index = results_df.index.to_series() \\\n                             .apply(lambda test_id: test_id.split('::')[-1])\n# (b) drop pytest object column\nresults_df.drop(['pytest_obj'], axis=1, inplace=True)\n</code></pre> <p>And finally we can use <code>pandas</code> or <code>tabulate</code> to export the result in csv or markdown format:</p> <pre><code># csv format\nprint(results_df.to_csv())\n\n# github markdown format\nfrom tabulate import tabulate\nprint(tabulate(results_df, headers='keys'))\n</code></pre> status duration_ms algo_param dataset accuracy test_my_app_bench[A-1] passed 1.00017 1 A 0.313807 test_my_app_bench[A-2] passed 0 2 A 0.0459802 test_my_app_bench[B-1] passed 0 1 B 0.638511 test_my_app_bench[B-2] passed 0 2 B 0.10418 test_my_app_bench[C-1] passed 0 1 C 0.287151 test_my_app_bench[C-2] passed 0 2 C 0.19437 <p>Duration calculation</p> <p>The duration field is directly extracted from <code>pytest</code>. Before version 6, <code>pytest</code> computed durations using the <code>time</code> method, which was not as accurate as other methods. From version 6 on, it uses <code>perf_counter()</code> (pytest#4391 was fixed). If you need to measure the duration of a specific sub-function instead of the duration of the whole test function call, use pytest-benchmark.</p>"},{"location":"advanced_usage/#5-partial-synthesis-module-function-and-synthesis-tests","title":"5- Partial synthesis (module, function) and synthesis tests","text":"<p>We have seen above that you can get the pytest <code>session</code> object from many different teardown hooks. In addition, you can even access it from inside a test! In that case all information will not be available, but if the synthesis test is located after the test function of interest in execution order, it will be ok.</p> <p>To be sure to only get results you're interested in, the special <code>filter</code> argument allows you to only select parts of the test nodes to create the synthesis:</p> <pre><code># a module-scoped store\n@pytest.fixture(scope='module', autouse=True)\ndef store():\n    return OrderedDict()\n\n# results bag fixture\nmy_results = create_results_bag_fixture('store', name='my_results')\n\ndef test_foo(my_results):\n    ...\n\ndef test_synthesis(request, store):\n    # get partial results concerning `test_foo`\n    results_dct = get_session_synthesis_dct(request.session, filter=test_foo, \n                                            fixture_store=store)\n\n    # you can assert / report using the `results_dct` here\n</code></pre> <p>See <code>help(get_session_synthesis_dct)</code> for details: for example you can include in this filter a list, and it can contain module names too.</p>"},{"location":"advanced_usage/#complete-example","title":"Complete example","text":"<p>A module-scoped complete example with parameters, fixtures, and results bag can be found in two versions:</p> <ul> <li>here with no customization (leveraging the default fixtures)</li> <li>here to perform the exact same behaviour but with custom store and results bag.</li> </ul>"},{"location":"api_reference/","title":"API reference","text":""},{"location":"api_reference/#1-available-fixtures","title":"1. Available fixtures","text":"<p>The following fixtures can be used in your tests as soon as the library is installed (no explicit plugin activation is required).</p>"},{"location":"api_reference/#results_bag","title":"<code>results_bag</code>","text":"<p>A \"results bag\" fixture: a dictionary where you can store anything (results, context, etc.) during your tests execution. It offers a \"much\"-like api: you can access all entries using the object protocol such as in <code>results_bag.a = 1</code>.</p> <p>This fixture has function-scope so a new, empty instance is injected in each test node. </p> <p>There are several ways to gather all results after they have been stored. </p> <ul> <li> <p>To get the raw stored results, use the <code>fixture_store</code> fixture: <code>fixture_store['results_bag']</code> will contain all result bags for all tests.</p> </li> <li> <p>If you are interested in both the stored results AND some stored fixture values (through <code>@saved_fixture</code>), you might rather wish to leverage the following helpers:</p> <ul> <li> <p>use one of the <code>session_results_dct</code>, <code>module_results_dct</code>, <code>session_results_df</code> or <code>module_results_df</code> fixtures. They contain all available information, in a nicely summarized way.</p> </li> <li> <p>use the <code>get_session_synthesis_dct(session)</code> helper method to create a similar synthesis than the above with more customization capabilities.</p> </li> </ul> </li> </ul> <p>If you wish to create custom results bags similar to this one (for example to create several with different names), use <code>create_results_bag_fixture</code>.</p> <p>See basic and advanced documentation for details.</p>"},{"location":"api_reference/#fixture_store","title":"<code>fixture_store</code>","text":"<p>A 'fixture store' fixture: a dictionary where fixture instances can be saved.</p> <p>By default</p> <ul> <li>all fixtures decorated with <code>@saved_fixture</code> are saved in this store.</li> <li>the <code>results_bag</code> fixture is also saved in this store.</li> </ul> <p>To retrieve the contents of the store, you can:</p> <ul> <li>create a test using this fixture and make sure that it is executed after all others. </li> <li>access this fixture from a dependent fixture and read its value in the setup or teardown script.</li> <li>access this fixture from the <code>request</code> fixture using the <code>get_fixture_value</code> helper method.</li> </ul> <p>This fixture has session scope so it is unique across the whole session. </p>"},{"location":"api_reference/#session_results_dct","title":"<code>session_results_dct</code>","text":"<p>This fixture contains a synthesis dictionary for all tests completed \"so far\", with 'full' id format. It includes contents from the default <code>fixture_store</code>, including <code>results_bag</code>.</p> <p>Behind the scenes it relies on <code>get_session_synthesis_dct</code>.</p> <p>This fixture has a function scope because we want its contents to be refreshed every time it is needed.</p> <p>See documentation for details.</p>"},{"location":"api_reference/#module_results_dct","title":"<code>module_results_dct</code>","text":"<p>Same than <code>session_results_dct</code> but with module scope.</p>"},{"location":"api_reference/#session_results_df","title":"<code>session_results_df</code>","text":"<p>This fixture contains a synthesis dataframe for all tests completed \"so far\" in the module of the caller, with 'function' id format. It includes contents from the default <code>fixture_store</code>, including <code>results_bag</code>.</p> <p>It is basically just a transformation of the <code>session_results_dct</code> fixture into a pandas <code>DataFrame</code>.</p> <p>If <code>pytest-steps</code> is installed, the step ids will be extracted and the dataframe index will be multi-level (test id without step, step id).</p> <p>This fixture has a function scope because we want its contents to be refreshed every time it is needed.</p> <p>See documentation for details.</p>"},{"location":"api_reference/#module_results_df","title":"<code>module_results_df</code>","text":"<p>Same than <code>session_results_df</code> but with module scope.</p>"},{"location":"api_reference/#associated-getter-functions","title":"Associated getter functions","text":"<p>For each of the above <code>[module/session]_results_[dct/df]</code> fixtures, an equivalent <code>get_&lt;fixture_name&gt;(session, ...)</code> is available. This allows users to access the same level of functionality than the fixture, in places where fixtures are not available (typically in a pytest hook such as the <code>pytest_sessionfinish</code> session finish hook)</p>"},{"location":"api_reference/#2-additional-symbols","title":"2. Additional symbols","text":""},{"location":"api_reference/#a-basic","title":"a- Basic","text":""},{"location":"api_reference/#saved_fixture","title":"<code>@saved_fixture</code>","text":"<pre><code>@saved_fixture(store='fixture_store',  # type: Union[str, Dict[str, Any]]\n               key=None,               # type: str\n               views=None,             # type: Dict[str, Callable[[Any], Any]]\n               save_raw=None,          # type: bool\n               )\n</code></pre> <p>Decorates a fixture so that it is saved in <code>store</code>. <code>store</code> can be a dict-like variable or a string representing a fixture name to a dict-like session-scoped fixture. By default it uses the global 'fixture_store' fixture provided by this plugin.</p> <p>After executing all tests, <code>&lt;store&gt;</code> will contain a new item under key <code>&lt;key&gt;</code> (default is the name of the fixture). This item is a dictionary :  for each test node where the fixture was setup. <pre><code>import pytest\nfrom pytest_harvest import saved_fixture\n\n@pytest.fixture\n@saved_fixture\ndef dummy():\n    return 1\n\ndef test_dummy(dummy):\n    pass\n\ndef test_synthesis(fixture_store):\n    print(fixture_store['dummy'])\n</code></pre> <p>Note that for session-scoped and module-scoped fixtures, not all test ids will appear in the store - only those for which the fixture was (re)created.</p> <p>Users can save additional views created from the fixture instance by applying transforms (callable functions). To do this, users can provide a dictionary under the <code>views</code> argument, containing a <code>{&lt;key&gt;: &lt;procedure&gt;}</code> dict-like. For each entry, <code>&lt;procedure&gt;</code> will be applied on the fixture instance, and the result will be stored under <code>&lt;key&gt;</code>. <code>save_raw</code> controls whether the fixture instance should still be saved in this case (default: <code>True</code> if <code>views is None</code>, <code>False</code> otherwise).</p> <p>Parameters</p> <ul> <li>store: a dict-like object or a fixture name corresponding to a dict-like object. in this dictionary, a new entry will be added for the fixture. This entry will contain a dictionary :  for each test node. By default fixtures are stored in the `fixture_store``fixture. <li>key: the name associated with the stored fixture in the store. By default this is the fixture name.</li> <li>views: an optional dictionary that can be provided to store views created from the fixture, rather than (or in addition to, if <code>save_raw=True</code>) the fixture itself. The dict should contain a <code>{&lt;key&gt;: &lt;procedure&gt;}</code> dict-like. For each entry, <code>&lt;procedure&gt;</code> will be applied on the fixture instance, and the result will be stored under <code>&lt;key&gt;</code>.</li> <li>save_raw: controls whether the fixture instance should be saved. <code>None</code> (Default) is an automatic behaviour meaning \"<code>True</code> if <code>views is None</code>, <code>False</code> otherwise\".</li> <p>Returns: a fixture that will be stored</p> <p>See basic and advanced documentation for details.</p>"},{"location":"api_reference/#resultsbag-class","title":"<code>ResultsBag</code> class","text":"<p>The default type for result bags, used in the <code>results_bag</code> fixture and <code>create_results_bag_fixture</code> method.</p> <p>It is a simple 'Munch', that is, a dual object/dict. It is hashable with a not very interesting hash, but at least a unique one in a python session (id(self)).</p>"},{"location":"api_reference/#b-intermediate","title":"b- Intermediate","text":""},{"location":"api_reference/#create_results_bag_fixture","title":"<code>create_results_bag_fixture(...)</code>","text":"<pre><code>create_results_bag_fixture(store,               # type: Union[str, Dict[str, Any]]\n                           name='results_bag',  # type: str\n                           bag_type=None,       # type: Type[Any]\n                           )\n</code></pre> <p>Creates a \"results bag\" fixture with name <code>name</code> stored in the given store (under key=<code>name</code>). By default results bags are instances of <code>ResultsBag</code> but you can provide another <code>bag_type</code> if needed.</p> <p>Parameters</p> <ul> <li> <p>store: a dict-like object or a fixture name corresponding to a dict-like object. in this dictionary, a new entry will be added for the fixture. This entry will contain a dictionary :  for each test node. <li> <p>name: the name associated with the stored fixture in the global store. By default this is 'results_bag'.</p> </li> <li> <p>bag_type: the type of object to create as a results bag. Default: <code>ResultsBag</code></p> </li>"},{"location":"api_reference/#c-advanced","title":"c- Advanced","text":""},{"location":"api_reference/#get_fixture_storesession","title":"<code>get_fixture_store(session)</code>","text":"<p>The default fixture store, that is also available through the <code>fixture_store</code> fixture, is <code>FIXTURE_STORE</code>. Accessing it directly might be needed in some cases where fixtures are not available (typically in some pytest hooks). However to be pytest xdist compliant, users should rather use <code>get_fixture_store(session)</code> in these cases.</p>"},{"location":"api_reference/#get_session_synthesis_dct","title":"<code>get_session_synthesis_dct(...)</code>","text":"<pre><code>get_session_synthesis_dct(session_or_request,\n                          test_id_format='full',   #\n                          status_details=False,    # type: bool\n                          durations_in_ms=False,   # type: bool\n                          pytest_prefix=None,      # type: bool\n                          filter=None,             # type: Any\n                          filter_incomplete=True,  # type: bool\n                          flatten=False,           # type: bool\n                          fixture_store=None,      # type: Union[Mapping[str, Any], Iterable[Mapping[str, Any]]]\n                          flatten_more=None        # type: Union[str, Iterable[str], Mapping[str, str]]\n                          )\n</code></pre> <p>Returns a dictionary containing a synthesis of what is available currently in the provided <code>pytest</code> <code>session</code> object.</p> <p>For each entry, the key is the test id, and the value is a dictionary containing:</p> <ul> <li><code>'pytest_obj'</code>: the object under test, typically a test function</li> <li><code>'pytest_status'</code>: the overall status (<code>'failing'</code>, <code>'skipped'</code>, <code>'passed'</code>)</li> <li><code>'pytest_duration'</code>: the duration of the <code>'call'</code> step. By default this is the pytest unit (s) but if you set <code>durations_in_ms=True</code> it becomes (ms)</li> <li><code>'pytest_status_details'</code>: a dictionary containing step-by-step status details for all pytest steps (<code>'setup'</code>, <code>'call'</code>, <code>'teardown'</code>). This is only included if <code>status_details=True</code> (not by default)</li> </ul> <p>It is possible to process the test id (the keys) using the <code>test_id_format</code> option. Let's assume that the id is </p> <p><code>pytest_steps/tests_raw/test_wrapped_in_class.py::TestX::()::test_easy[p1-p2]</code>. </p> <p>Here are the returned test ids depending on the selected <code>test_id_format</code></p> <ul> <li><code>'function'</code> will return <code>test_easy[p1-p2]</code></li> <li><code>'class'</code> will return <code>TestX::()::test_easy[p1-p2]</code></li> <li><code>'module'</code> will return <code>test_wrapped_in_class.py::TestX::()::test_easy[...]</code></li> <li><code>'full'</code> will return the original id (this is the default behaviour)</li> </ul> <p>In addition one can provide a custom string handling function that will be called for each test id to process.</p> <p>The 'pytest' prefix in front of all these items (except <code>pytest_obj</code>) is by default added in non-flatten mode and removed in flatten mode. To force one of these you can set <code>pytest_prefix</code> to <code>True</code> or <code>False</code>.</p> <p>An optional <code>filter</code> can be provided, that can be a singleton or iterable of pytest objects (typically test functions) and/or module names.</p> <p>If this method is called before the end of the pytest session, some nodes might be incomplete, i.e. they will not have data for the three stages (setup/call/teardown). By default these nodes are filtered out but you can set <code>filter_incomplete=False</code> to make them appear. They will have a special 'pending' synthesis status.</p> <p>An optional collection of storage objects can be provided, so as to merge them into the resulting dictionary.</p> <p>Finally a <code>flatten_output</code> option allows users to get a flat dictionary output instead of nested status details, parameters dict, and storage dicts.</p> <p>Parameters:</p> <ul> <li>session: a pytest session object.</li> <li>test_id_format: one of 'function', 'class', 'module', or 'full' (default), or a custom test id processing function.</li> <li>status_details: a flag indicating if pytest status details per stage (setup/call/teardown) should be included. Default=<code>False</code>: only the pytest status summary is provided.</li> <li>durations_in_ms: by default <code>pytest</code> measures durations in seconds so they are outputed in this unit. You can turn the flag to True to output milliseconds instead.</li> <li>pytest_prefix: to add (True) or remove (False) the 'pytest_' prefix in front of status, duration and status details. Typically useful in flatten mode when the names are not ambiguous. By default it is None, which means =(not flatten)</li> <li>filter: a singleton or iterable of pytest objects on which to filter the returned dict on (the returned items will only by pytest nodes for which the pytest object is one of the ones provided). One can also use module names. See <code>pytest_item_matches_filter</code>.</li> <li>filter_incomplete: a boolean indicating if incomplete nodes (without the three stages setup/call/teardown)     should appear in the results (False) or not (True, default).</li> <li>flatten: a boolean (default <code>False</code>) indicating if the resulting dictionary should be flattened. If it set to <code>True</code>, the 3 nested dictionaries (pytest status details, parameters, and optionally storages) will have their contents directly copied in the first level (with a prefix added in case of pytest status details).</li> <li>fixture_store: a singleton or iterable containing dict-like fixture storage objects (see <code>@saved_fixture</code> and <code>create_results_bag_fixture</code>). If flatten=<code>False</code> the contents of these dictionaries will be added to the output in a dedicated 'fixtures' entry. If flatten=True all of their contents will be included directly.</li> <li>flatten_more: a singleton, iterable or dictionary containing fixture names to flatten one level more in case flatten=True. If a dictionary is provided, the key should be the fixture name, and the value should be a prefix used for flattening its contents</li> </ul> <p>Returns: a dictionary where the keys are pytest node ids. Each value is also a dictionary, containing information available from pytest concerning the test node, and optionally storage contents if <code>storage_dcts</code> is provided.</p>"},{"location":"api_reference/#filter_session_items","title":"<code>filter_session_items(...)</code>","text":"<pre><code>filter_session_items(session,\n                     filter=None,  # type: Any\n                     )\n</code></pre> <p>Filters pytest session item in the provided <code>session</code>. An optional <code>filter</code> can be provided, that can be a singleton or iterable of pytest objects (typically test functions) and/or module names.</p> <p>Used in <code>get_session_synthesis_dct</code>.</p> <p>Parameters</p> <ul> <li>session: a pytest session</li> <li>filter: a singleton or iterable of pytest objects on which to filter the returned dict on (the returned items will only by pytest nodes for which the pytest object is one of the ones provided). One can also use module names.</li> </ul> <p>Returns: an iterable containing possibly filtered session items</p>"},{"location":"api_reference/#pytest_item_matches_filter","title":"<code>pytest_item_matches_filter(...)</code>","text":"<pre><code>pytest_item_matches_filter(item, filter)\n</code></pre> <p>Returns <code>True</code> if pytest session item <code>item</code> matches filter <code>filter</code>, <code>False</code> otherwise.</p>"},{"location":"api_reference/#d-pytest-utils","title":"d- Pytest utils","text":""},{"location":"api_reference/#get_all_pytest_fixture_names","title":"<code>get_all_pytest_fixture_names(...)</code>","text":"<pre><code>get_all_pytest_fixture_names(session,\n                             filter=None,              # type: Any\n                             filter_incomplete=False,  # type: bool\n                             )\n</code></pre> <p>Returns the list of all unique fixture names used in all items in the provided session, with given filter.</p> <p>An optional <code>filter</code> can be provided, that can be a singleton or iterable of pytest objects (typically test functions) and/or module names.</p> <p>If this method is called before the end of the pytest session, some nodes might be incomplete, i.e. they will not have data for the three stages (setup/call/teardown). By default these nodes are filtered out but you can set <code>filter_incomplete=False</code> to make them appear. They will have a special 'pending' synthesis status.</p> <p>Parameters</p> <ul> <li>session: a pytest session object.</li> <li>filter: a singleton or iterable of pytest objects on which to filter the returned dict on (the returned items will only by pytest nodes for which the pytest object is one of the ones provided). One can also use modules.</li> <li>filter_incomplete: a boolean indicating if incomplete nodes (without the three stages setup/call/teardown) should appear in the results (False) or not (True). Note: by default incomplete nodes DO APPEAR (this is different from get_session_synthesis_dct behaviour)</li> </ul> <p>Returns: a list of fixture names corresponding to the desired filters</p>"},{"location":"api_reference/#get_all_pytest_param_names","title":"<code>get_all_pytest_param_names(...)</code>","text":"<pre><code>get_all_pytest_param_names(session,\n                           filter=None,              # type: Any\n                           filter_incomplete=False,  # type: bool\n                           )\n</code></pre> <p>Returns the list of all unique parameter names used in all items in the provided session, with given filter.</p> <p>An optional <code>filter</code> can be provided, that can be a singleton or iterable of pytest objects (typically test functions) and/or module names.</p> <p>If this method is called before the end of the pytest session, some nodes might be incomplete, i.e. they will not have data for the three stages (setup/call/teardown). By default these nodes are filtered out but you can set <code>filter_incomplete=False</code> to make them appear. They will have a special 'pending' synthesis status.</p> <p>Parameters</p> <ul> <li>session: a pytest session object.</li> <li>filter: a singleton or iterable of pytest objects on which to filter the returned dict on (the returned items will only by pytest nodes for which the pytest object is one of the ones provided). One can also use modules.</li> <li>filter_incomplete: a boolean indicating if incomplete nodes (without the three stages setup/call/teardown) should appear in the results (False) or not (True). Note: by default incomplete nodes DO APPEAR (this is different from get_session_synthesis_dct behaviour)</li> </ul> <p>Returns: a list of parameter names corresponding to the desired filters</p>"},{"location":"api_reference/#get_fixture_value","title":"<code>get_fixture_value(...)</code>","text":"<p><code>get_fixture_value(request, fixture_name)</code></p> <p>Returns the value associated with fixture named <code>fixture_name</code>, in provided <code>request</code> context. This is just an easy way to use <code>getfixturevalue</code> or <code>getfuncargvalue</code> according to whichever is available in current <code>pytest</code> version.</p>"},{"location":"api_reference/#get_pytest_status","title":"<code>get_pytest_status(...)</code>","text":"<p><code>get_pytest_status(item, durations_in_ms=False, current_request=None)</code></p> <p>Returns a dictionary containing item's pytest status (success/skipped/failed, duration converted to ms) for each pytest phase, and a tuple synthesizing the information.</p> <p>The synthesis status contains the worst status of all phases (setup/call/teardown), or 'pending' if there are less than 3 phases.</p> <p>The synthesis duration is equal to the duration of the 'call' phase (not to the sum of all phases: indeed, we are mostly interested in the test call itself).</p> <p>Parameters</p> <ul> <li>item: a pytest session.item</li> <li>durations_in_ms: by default <code>pytest</code> measures durations in seconds so they are outputed in this unit. You can turn the flag to True to output milliseconds instead.</li> <li>current_request: if a non-None <code>request</code> is provided and the item is precisely the one from the request, then the status will be 'pending'</li> </ul> <p>Returns: a tuple ((test_status, test_duration), status_dct)</p>"},{"location":"api_reference/#is_pytest_incomplete","title":"<code>is_pytest_incomplete(...)</code>","text":"<p><code>is_pytest_incomplete(item)</code></p> <p>Returns <code>True</code> if a pytest item is incomplete - in other words if at least one of the 3 steps (setup/call/teardown) is missing from the available pytest report attached to this item.</p>"},{"location":"api_reference/#get_pytest_param_names","title":"<code>get_pytest_param_names(...)</code>","text":"<p><code>get_pytest_param_names(item)</code></p> <p>Returns a list containing a pytest session item's parameters.</p>"},{"location":"api_reference/#get_pytest_params","title":"<code>get_pytest_params(...)</code>","text":"<p>Returns a dictionary containing a pytest session item's parameters.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#1106-bugfixes-and-maintenance-chores","title":"1.10.6 - bugfixes and maintenance chores","text":"<ul> <li>Refactored layout and CI. Fixed #56.</li> </ul>"},{"location":"changelog/#1105-pytest-81-compat","title":"1.10.5 - pytest 8.1 compat","text":"<p>PR #70 to ensure pytest 8.1 compatibility, including:</p> <ul> <li>Fixed issue with <code>pytest&gt;=8.1</code>: Fixed <code>AttributeError: 'str' object has no attribute 'iter_parents'</code>,    #68. Initial proposal in PR    #67 by @larsoner.</li> <li>Fixed issue with <code>pytest&gt;=8.1</code>: Adapt to <code>getfixturedefs</code> signature change, initial proposal in PR    #65 by @bluetech.</li> </ul> <p>Dropped support for pytest 2. Issue #66.</p>"},{"location":"changelog/#1104-python-35-xdist-bugfix","title":"1.10.4 - python 3.5 xdist bugfix","text":"<ul> <li>Fixed issue with <code>pytest-xdist</code> and python 3.5: <code>pathlib</code> objects were not properly handled by other stdlib modules in this python version. Fixed #59</li> <li>Changed the layout</li> </ul>"},{"location":"changelog/#1103-xdist-bugfix-lazy-pandas-loading","title":"1.10.3 - xdist bugfix + lazy <code>pandas</code> loading","text":"<ul> <li> <p><code>pandas</code> is now only imported when used, to speed up boot time. Fixes #49</p> </li> <li> <p>Fixed issue with latest <code>pytest</code>+<code>pytest-xdist</code> versions: <code>pytest_harvest_xdist_worker_dump</code> hook is now called correctly. Fixes #48</p> </li> </ul>"},{"location":"changelog/#1102-cicd-change","title":"1.10.2 - CI/CD change","text":"<ul> <li>This is a technical release to validate that migration to Github Actions worked.</li> </ul>"},{"location":"changelog/#1101-now-supporting-in-test-ids","title":"1.10.1 - Now supporting <code>::</code> in test ids","text":"<ul> <li><code>get_session_synthesis_dct</code> now properly handles test ids where <code>::</code> is present in the id. This fix propagates to all <code>[module/session]_results_[dct/df]</code> fixtures, too. Fixes #45</li> </ul>"},{"location":"changelog/#1100-fixed-issue-on-old-pytest","title":"1.10.0 - Fixed issue on old pytest","text":"<ul> <li>On pytest &lt; 5.3, <code>lazy_value</code> parameters from <code>pytest-cases</code> were wrongly inserted in the <code>module_results_df</code> as integer instead of objects. Fixed #43 thanks to new <code>pytest-cases</code> 2.3.0.</li> </ul>"},{"location":"changelog/#193-fixed-support-for-doctests","title":"1.9.3 - Fixed support for doctests","text":"<ul> <li>Fixed issue with doctests. PR #41 by @larsoner</li> </ul>"},{"location":"changelog/#192-bugfix","title":"1.9.2 - bugfix","text":"<ul> <li>Fixed issue sometimes happening when xdist is not installed. Fixed #40</li> </ul>"},{"location":"changelog/#191-better-packaging","title":"1.9.1 - better packaging","text":"<ul> <li>packaging improvements: set the \"universal wheel\" flag to 1, and cleaned up the <code>setup.py</code>. In particular removed dependency to <code>six</code> for setup and added <code>py.typed</code> file, as well as set the <code>zip_safe</code> flag to False. Removed tests folder from package. Fixes #38</li> </ul>"},{"location":"changelog/#190-better-pytest-xdist-support","title":"1.9.0 - better pytest-xdist support","text":"<p>When <code>pytest-xdist</code> is used to distribute tests, worker node results are automatically stored in a file at the end of their respective pytest session using pickle, in a temporary <code>.xdist_harvested/</code> folder. These results are automatically retrived and consolidated when any of the <code>get_[module/session]_results_[dct/df]</code> method is called from the master node. Finally, the temporary folder is deleted at the end of master node session. Fixes #36</p> <p>New function <code>get_fixture_store(session)</code> to replace <code>FIXTURE_STORE</code>. It is robust to xdist distribution, hence preferred over direct use of <code>FIXTURE_STORE</code>.</p>"},{"location":"changelog/#180-pytest-xdist-compliance","title":"1.8.0 - pytest-xdist compliance","text":"<ul> <li> <p>For each of the <code>[module/session]_results_[dct/df]</code> fixtures, an equivalent <code>get_&lt;fixture_name&gt;(session, ...)</code> helper function is available. This allows users to access the same level of functionality than the fixture, in places where fixtures are not available (typically in a pytest hook such as the <code>pytest_sessionfinish</code> session finish hook). In addition the default <code>FIXTURE_STORE</code> is now a package variable, available directly or through the session-scoped <code>fixture_store</code> fixture. Fixed #33 and #34.</p> </li> <li> <p>Added an example in the documentation on how to use with pytest-xdist. Fixes #32</p> </li> </ul>"},{"location":"changelog/#174-pyprojecttoml","title":"1.7.4 - <code>pyproject.toml</code>","text":"<p>Added a <code>pyproject.toml</code> file.</p>"},{"location":"changelog/#173-python-2-bugfix","title":"1.7.3 - python 2 bugfix","text":"<p>Fixed issue happening with python 2 when <code>unicode_literals</code> are used in the parameters receiving string types. Fixed #28</p>"},{"location":"changelog/#172-added-__version__-attribute","title":"1.7.2 - added <code>__version__</code> attribute","text":"<p>Added <code>__version__</code> attribute at package level.</p>"},{"location":"changelog/#171-added-six-dependency","title":"1.7.1 - added <code>six</code> dependency","text":"<p>It was missing from <code>setup.py</code>.</p>"},{"location":"changelog/#170-saved_fixture-supports-all-scopes","title":"1.7.0 - <code>@saved_fixture</code> supports all scopes","text":"<ul> <li> <p>Session-scoped and Module-scoped fixtures are now supported by <code>@saved_fixture</code>. Fixes #17.</p> </li> <li> <p>Documentation: new API reference page.</p> </li> </ul>"},{"location":"changelog/#161-minor-improvements","title":"1.6.1 - Minor improvements","text":"<p>Renamed argument in <code>create_results_bag_fixture</code> to align with the name used in <code>saved_fixture</code> (<code>store</code> instead of <code>storage</code>)</p> <p>Now using <code>decopatch</code> for decorator creation. <code>make_saved_fixture</code> can thus be removed, and <code>saved_fixture</code> simplified.</p> <p>Now using latest <code>makefun&gt;=1.5</code> so that <code>saved_fixture</code> create proper fixture wrappers, using <code>@makefun.wraps</code>.</p>"},{"location":"changelog/#160-improved-saved_fixture-minor-dependency-change","title":"1.6.0 - improved <code>@saved_fixture</code> + minor dependency change","text":"<p>Users can now use <code>@saved_fixture</code> to save not only the fixture, but also some views created from it. This is interesting if each fixture is huge but users just want to save small aspects of it (name, size, etc.). Fixed #21.</p> <p>Dependency to <code>decorator</code> has been dropped and replaced with <code>makefun</code>.</p>"},{"location":"changelog/#150-bug-fixes-concerning-fixtures","title":"1.5.0 - Bug fixes concerning fixtures","text":"<p>The <code>fixture_store</code> fixture, provided by the plugin, does not have <code>autouse=True</code> anymore. Fixed #20.</p> <p><code>get_all_pytest_fixture_names</code> now returns fixtures that are indirectly parametrized, as well as fixtures that are not parametrized. Fixed #19.</p>"},{"location":"changelog/#143-better-exceptions-for-saved_fixture","title":"1.4.3 - Better exceptions for <code>@saved_fixture</code>","text":"<p>Now raising a better exception if <code>@saved_fixture</code> is used on session- or module-scope fixtures. Fixes #18</p>"},{"location":"changelog/#142-fixed-results-bags-in-presence-of-steps-2","title":"1.4.2 - Fixed results bags in presence of steps (2)","text":"<p>Another import error was causing results bag to be saved incorrectly in presence of steps.</p>"},{"location":"changelog/#141-fixed-results-bags-in-presence-of-steps","title":"1.4.1 - Fixed results bags in presence of steps","text":"<p>Results bags are now compliant with <code>pytest-steps</code>: there are now one per step. This fixed #16.</p>"},{"location":"changelog/#140-removed-integration-with-pytest_steps-in-default-fixtures","title":"1.4.0 - Removed integration with <code>pytest_steps</code> in default fixtures","text":"<p>Integrating <code>pytest-steps</code> in default fixtures seemed like a bad idea because it led to automatic behaviour that could silently raise warnings. Let <code>pytest-steps</code> handle it on its side.</p>"},{"location":"changelog/#130-better-integration-with-pytest_steps-in-default-fixtures","title":"1.3.0 - Better integration with <code>pytest_steps</code> in default fixtures","text":"<p>Default fixtures <code>module_results_df</code> and <code>session_results_df</code> now automatically become multi-level indexed when pytest steps is installed and there are steps in the tests.</p>"},{"location":"changelog/#121-minor-new-low-level-api","title":"1.2.1 - Minor: new low-level API","text":"<p>New method <code>get_all_pytest_fixture_names</code> to list all fixture names used by items in a session.</p>"},{"location":"changelog/#120-added-column-in-default-dataframe-synthesis-fixtures","title":"1.2.0 - Added column in default dataframe synthesis fixtures","text":"<p>Fixtures <code>module_results_df</code> and <code>session_results_df</code> now contains the <code>'pytest_obj'</code> column.</p>"},{"location":"changelog/#110-new-default-fixtures-fixture-parameter-names-fix","title":"1.1.0 - New default fixtures + fixture parameter names fix","text":"<p>Created 6 fixtures registered by default by the plugin. Fixed #14:</p> <ul> <li><code>fixture_store</code> in an <code>OrderedDict</code> that can be used as a fixture store, typically in <code>@saved_fixture</code>.</li> <li><code>results_bag</code> is a <code>ResultsBag</code>-typed results bag.</li> <li><code>session_results_dct</code> and <code>module_results_dct</code> return a synthesis dictionary for all tests completed \"so far\", respectively in the session or module. They include     contents from the default <code>fixture_store</code>, including <code>results_bag</code>.</li> <li><code>session_results_df</code> and <code>module_results_df</code> are the dataframe equivalents of <code>session_results_dct</code> and <code>module_results_dct</code></li> </ul> <p>The documentation has been updated so that users can get started more quickly by leveraging them.</p> <p>In addition:</p> <ul> <li><code>get_session_synthesis_dct</code> can now take both a <code>session</code> or a <code>request</code> input. If a <code>request</code> is provided, the status of current item will be marked as 'pending', while not started items will be marked as 'unknown'.</li> <li>fixed bug in <code>get_session_synthesis_dct</code>: fixture parameters and saved fixtures where overriding each other in the final dict in <code>flatten=True</code> mode. Now fixture parameters appear as <code>'&lt;fixture_name&gt;_param'</code>. Fixed #15.</li> <li><code>@saved_fixture</code> can now be used without arguments. By default it will store fixtures in the default session-scoped <code>'fixture_store'</code> fixture.</li> <li><code>HARVEST_PREFIX</code> moved to <code>common.py</code> and is now exported at package level.</li> </ul>"},{"location":"changelog/#101-ordering-bug-fix","title":"1.0.1 - Ordering bug fix","text":"<p>Fixed pytest ordering issue, by relying on place_as. See #18</p>"},{"location":"changelog/#100-new-methods-for-pytest-session-analysis","title":"1.0.0 - new methods for pytest session analysis","text":"<p>New methods are provided to analyse pytest session results:   - <code>filter_session_items(session, filter=None)</code> is the filtering method used behind several functions in this package - it can be used independently. <code>pytest_item_matches_filter</code> is the inner method used to test if a single item matches the filter.  - <code>get_all_pytest_param_names(session, filter=None, filter_incomplete=False)</code> lists all unique parameter names used in pytest session items, with optional filtering capabilities. Fixes #12  - <code>is_pytest_incomplete(item)</code>, <code>get_pytest_status(item)</code>, <code>get_pytest_param_names(item)</code> and <code>get_pytest_params(item)</code> allow users to analyse a specific item. </p>"},{"location":"changelog/#090-get_session_synthesis_dct-filter-bugfix-test-id-formatter","title":"0.9.0 - <code>get_session_synthesis_dct</code>: filter bugfix + test id formatter","text":"<ul> <li> <p><code>get_session_synthesis_dct</code>:</p> </li> <li> <p><code>filter</code> now correctly handles class methods. Fixed #11</p> </li> <li>new <code>test_id_format</code> option to process test ids. Fixed #9</li> </ul>"},{"location":"changelog/#080-documentation-better-filters-in-get_session_synthesis_dct","title":"0.8.0 - Documentation + better filters in <code>get_session_synthesis_dct</code>","text":"<ul> <li> <p>Documentation: added a section about creating the synthesis table from inside a test function (fixes #4). Also, added a link to a complete example file.</p> </li> <li> <p><code>get_session_synthesis_dct</code>: <code>filter</code> argument can now contain module names (fixed #7). Also now the function filters out incomplete tests by default. A new <code>filter_incomplete</code> argument can be used to display them again (fixed #8).</p> </li> </ul>"},{"location":"changelog/#070-documentation-get_session_synthesis_dct-improvements-2","title":"0.7.0 - Documentation + <code>get_session_synthesis_dct</code> improvements 2","text":"<ul> <li> <p>Results bags do not measure execution time anymore since this is much less accurate than pytest duration. Fixes #6</p> </li> <li> <p><code>get_session_synthesis_dct</code> does not output the stage by stage details (setup/call/teardown) anymore by default, but a new option <code>status_details</code> allows users to enable them. Fixes #5</p> </li> <li> <p><code>get_session_synthesis_dct</code> has also 2 new options <code>durations_in_ms</code> and <code>pytest_prefix</code> to better control the output.</p> </li> <li> <p>Improved documentation.</p> </li> </ul>"},{"location":"changelog/#060-get_session_synthesis_dct-improvements","title":"0.6.0 - <code>get_session_synthesis_dct</code> improvements","text":"<ul> <li><code>get_session_synthesis_dct</code> now has a test object <code>filter</code>, a <code>flatten</code> option, and and can now take optional storage objects as input to create a fully merged dictionary. See <code>help(get_session_synthesis_dct)</code> for details. Fixes #3.</li> </ul>"},{"location":"changelog/#051-fixed-bug-with-pytest-2x","title":"0.5.1 - Fixed bug with pytest 2.x","text":"<ul> <li>Fixed #2.</li> </ul>"},{"location":"changelog/#050-first-public-version","title":"0.5.0 - First public version","text":"<p>First version validated against the data science benchmark pattern (yet to be published)</p> <ul> <li><code>get_session_synthesis_dct</code> method to collect various test information already available</li> <li><code>@saved_fixture</code> decorator supports both a variable or a fixture for the storage</li> <li><code>create_results_bag_fixture</code> to create results bags</li> <li>Documentation</li> </ul>"},{"location":"long_description/","title":"pytest-harvest","text":"<p>Store data created during your <code>pytest</code> tests execution, and retrieve it at the end of the session, e.g. for applicative benchmarking purposes.</p> <p>The documentation for users is available here: https://smarie.github.io/python-pytest-harvest/</p> <p>A readme for developers is available here: https://github.com/smarie/python-pytest-harvest</p>"}]}